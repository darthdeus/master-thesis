\section{Acquisition functions}
\label{section:acq-fn}

An intuitive choice for an acquisition function is to maximize the probability
of improving over our currently best achieved value, which is called the
\newterm{probability of improvement}. This can be computed in closed form as
$$
PI(\vx) = Œ¶ \left( \frac{Œº(\vx) - y_{\max}}{œÉ(\vx)} \right)
$$
where $y_{\max}$ is the maximum value achieved by sampling $f(\vx)$.

A natural extension is the \newterm{expected improvement} (EI) acquisition function
which is simply the expected improvement over the currently achieved maximum.
We define it as $$EI(x) = ùîº[f(x) - y_{\max}].$$ At first it might seem that
the expectation would be an intractable integral, but fortunately even this
equation can be computed in closed form as
$$
EI(x) = Œî(x) + œÉ(x) œÜ \left( \frac{Œî(x)}{œÉ(x)} \right) - |Œî(x)| Œ¶ \left( \frac{Œî(x)}{œÉ(x)} \right)
$$
where $Œî(x) = Œº(x) - y_{\max}$. In practice, improvement shows better results
than probability of improvement. For more examples of acquisition functions see
\cite{frazier2018tutorial}.

In both of these cases, the next sampling point would be chosen by maximizing
the acquisition function, that is $$x_{\operatorname{next} = \argmax_x EI(x)$$ for
the case of expected improvement. This can again be done by any stochastic optimizer,
such as the commonly chosen L-BFGS with restarts.


\section{Parallel evaluations}

In practice we might have the ability to evaluate $f(\vx)$ at multiple points
in parallel, but the framework we have shown so far only allows for sequential
optimization. In the previous section we've shown a few examples of the
acquisition functions. A natural extension would be to not optimize with respect
to a single $x_\operatorname{next}$, but rather multiple points. In the context of
EI this is called \newterm{parallel expected improvemenet}.

Unfortunately, there is no simple solution \citep{frazier2018tutorial}. A
common solution is the so called \newterm{Constant Liar} approximation, which
chooses $x_{i+1}$ assuming $x_i$ was already chosen, and has the corresponding
value $y_i$ equal to a constant, often chosen to be the expected value of
$f(x_i)$ under the GP posterior.

This allows us to trivially implement parallel evaluations by simply
considering the $Œº$ prediction for unfinished evaluations as their $y$ value
and consider them part of the dataset $ùìì$.


\section{Integer parameters}



\section{bopt algorithm}

matematika

\section{Logscale}

% \subsection{Expected Improvement}
%
% \newterm{Expected improvement} $EI(x)$ is defined as
%
% \begin{equation}
%   EI(x) = E_{Y \sim \gN(\mu, \sigma^2)} [max(f(x) - f(x^+), 0)]
% \end{equation}
%
% where $f(x^+)$ is the value of the best sample so far and $x^+ =
% \argmax_{x_i \in x_{1:t}} f(x_i)$.
%
% \subsection{Probability of Improvement}
%
% We add a small term $\xi$ because otherwise $PI(x^+) = \frac{1}{2}.$
%
% \begin{align}
%   PI(x) &= P(f(x) \geq \mu^+ + \xi) \\
%         &= \Phi \left(\frac{\mu(x) - \mu^+ - \xi}{\sigma(x)} \right)
% \end{align}
%
% where $\Phi$ is the CDF of a Gaussian. If we knew up front what is the best
% value $f(x^*)$ we can model that directly by $P(f(x) \geq f(x^*))$.
%
%
% \subsection{GP-UCB}
%
% Define the \newterm{regret} and \newterm{cumulative regret} as follows:
%
% \begin{align}
%   r(x) &= f(x^*) - f(x) \\
%   R_T &= r(x_1) + \cdots + r(x_T).
% \end{align}
%
% The GP-UCB criterion is as follows:
%
% \begin{align}
%   GP-UCB(x) = \mu(x) + \sqrt{\nu \beta} \sigma(x)
% \end{align}
%
% with $\nu = 1$ and $\beta_t = 2 \log(t^{d/2 + 2}\pi^2 / 3 \delta)$ where it can
% be shown with high probability that this method has no regret, i.e. $\lim_{T
% \rightarrow \infty} R_T / T = 0$. (Srinivas et at, 2010 TODO REF). (NOTE, if
% the set of points is not infinite, $\beta$ ends up being different).
%
%
% \section{Algorithm}
%
% TODO
%
% \section{Parallel Evaluations}
%
% TODO
