\chapter{Introduction}
intro (2 stranky)
  - co jous hyperparam, ze to model neumi nastavit, atd.
  - proc chceme delat black box, ...

\section{Our Contributions}
- co jsme udelali


\chapter{Bayesian Optimization overview}

- intro co mam
- acq fce

\section{Related work}
\section{Hyperparam vs. Architecture Search}
\section{Diskretni hyperparam vs onehot vs ...}


\chapter{Gaussian Processes}

- ucbnicove
- uvod, proc to delame
- kernely existujou

\chapter{Bayesian Optimization in depth}

- bopt alg
- jaky kernely v bayes opt., co pouzivame, proc (ref)


\chapter{Software}

- co umime
- vizualizace
- jak se to pousti, runnery, serializace

\chapter{Experiments}

- toy tasky
  - porovnani existujici fuj fce na optimalizaci
  - srovnani acq/kernel, random search (ze to neco dela)

- maly ulohy

- velka uloha

- interpretace vysledku



- parser
- tokenizer/segmentace
- speech recognition
- opennmt lemmatizace
- reinforce_with_baseline





\section{Bayesian Optimization}

Consider the problem of optimizing an arbitrary continuous function $f: ùìß ‚Üí ‚Ñù$
where $ùìß ‚äÇ ‚Ñù^d, d ‚àà ‚Ñï$. We call $f$ the \emph{objective function} and treat it
as a black box, making no assumption on its analytical form, or on our ability
to compute its derivatives. Our goal is to find the global minimum
$\symbf{x}_\text{opt}$ over the set $ùìß$, that is
$$
\symbf{x}_\text{opt} = \arg\min_{\symbf{x} ‚àà ùìß} f(\symbf{x}).
$$

We also assume that the evaluation of $f$ is expensive, as the goal of Bayesian
optimization is to find the optimum as quickly as possible.  Consider the case
when evaluating $f$ means performing a computation that is not only time
consuming, but for example also costs a lot of money. We might only have a
fixed budget which puts a hard limit on the number of evaluations we can
perform.

If the function can be evaluated cheaply, other global optimization approaches
such as simulated annealing or evolution strategies could potentially yield
better results (TODO ref).


Bayesian optimization techniques are some of the most efficient approaches in
terms of the number of function evaluations required. Much of the efficiency
stems from the ability to incorporate prior belief about the problem and to
trade of exploration and exploitation of the search space. [Nando 2012] It is
called Bayesian because it combines the prior knowledge $p(f)$ about the
function together with the data in the form of the likelihood $p(x|f)$ to
formulate a posterior distribution on the set of possible functions $p(f|x)$.
We will use the posterior distribution to figure out which point should be
evaluated next to give a likely improvement over the currently obtained
maximum.

---

Let $ùìì_n = \{ (\symbf{x}_i, y_i), i \in 1:n\}$ denote a set of $n$ samples
(evaluations) of the function $f$, that is $y_i = f(\symbf{x}_i)$. Our goal is
to pick the next $\symbf{x}_{n+1}$ to maximize our chance of finding the
optimum quickly.

Consider the set of all continuous functions $f ‚àà ùìï$ with a prior distribution
$p(f)$.  Conditioning on our samples gives us a posterior distribution over
possible functions $p(f | ùìì)$.

---

