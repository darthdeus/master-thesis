\chapter{Appendix?}

\section{Cholesky Decomposition}

\begin{defn}
    The \newterm{Cholesky decomposition} is a decomposition of a positive-definite matrix into a product of a lower triangular matrix and its conjugate transpose. Since we will only work with symmetric positive-definite matrices we omit the conjugacy and define Cholesky decomposition as

        \begin{equation}
            \mA = \mL \mL^T
        \end{equation}
        
    where $\mL$ is a lower triangular matrix called the \newterm{Cholesky factor}.
\end{defn}

Because of its numerical stability, Cholesky decomposition is useful for solving systems of linear equations $\mA \vx = \vb$ where $\mA$ is symmetric and positive definite. We do this by first solving the triangular system $\mL \vy = \vb$ by forward substitution, and then the triangular system $\mL^T \vx = \vy$ by back substitution. This works because

\begin{align}
    \mA \vx &= \vb \qquad \text{assuming $\mA$ is symmetric positive-definite} \\
    \mL\mL^T \vx &= \vb \\
    \mL \vy &= \vb \\
    \mL^T \vx &= \vy \qquad \text{which if we back-substitute $\vy$} \\
    \mL (\mL^T \vx) &= \vy \qquad \text{using associativity} \\
    (\mL \mL^T) \vx &= \mA \vx = \vy.
\end{align}

For brevity, we'll apply the MATLAB {TODO ref} backslash operator where $\mA \backslash \vb = \vx$, which allows us to write the above as $\vx = \mL^T \backslash (\mL \backslash b)$.


\section{TODO Bucket}

\begin{thm}[\citep{murphy2012machine}] (Inverse of a partitioned matrix). Consider a partitioned matrix

\begin{equation}
\mM = \begin{bmatrix} \mA & \mB \\ \mC & \mD \end{bmatrix}
\end{equation}

where we assume $\mA$ and $\mD$ are invertible {TODO staci to? nemusi byt i ty ostatni?}. We have

\begin{equation}
\mM^{-1} = \begin{bmatrix} \mI & \mZero \\ \mI & \mI \end{bmatrix}
\end{equation}
\end{thm}

\begin{proof}
All we need to do is perform a block \newterm{LDU decomposition} and we directly arrive at our solution. We begin by zeroing out $\mB$.

\begin{equation} \label{eq:block-ld-part}
\begin{bmatrix} \mI & -\mB \mD^{-1} & \\ \mZero & \mI \end{bmatrix}
\begin{bmatrix}\mA & \mB \\ \mC & \mD \end{bmatrix} =
\begin{bmatrix} \mA - \mB \mD^{-1} \mC & \mZero \\ \mC & \mD \end{bmatrix}
\end{equation}

The quantity in the top left block is called a \newterm{Schur complement} of $\mM$ wrt $\mD$. We denote it as follows, and also define a variant for the bottom right block

\begin{align}
\mM/\mD &= \mA - \mB \mD^{-1} \mC \\
\mM/\mA &= \mD - \mC \mA^{-1} \mB
\end{align}

Substituting back into \eqref{eq:block-ld-part} we get the following

\begin{equation}
\begin{bmatrix} \mM/\mD & \mZero \\ \mC & \mD \end{bmatrix}
\end{equation}

We follow by eliminating the bottom left block in \eqref{eq:block-ld-part}

\begin{equation} \label{eq:block-du-part}
\begin{bmatrix} \mM/\mD & \mZero \\ \mC & \mD \end{bmatrix}
\begin{bmatrix} \mI & \mZero \\ -\mD^{-1} \mC & \mI \end{bmatrix} =
\begin{bmatrix} \mM/\mD & \mZero \\ \mZero & \mD \end{bmatrix}
\end{equation}

Putting together \eqref{eq:block-ld-part} and \eqref{eq:block-du-part} we get

\begin{equation}
\underbrace{\begin{bmatrix} \mI & -\mB \mD^{-1} & \\ \mZero & \mI \end{bmatrix}}_{\mX}
\underbrace{\begin{bmatrix}\mA & \mB \\ \mC & \mD \end{bmatrix}}_{\mM}
\underbrace{\begin{bmatrix} \mI & \mZero \\ -\mD^{-1} \mC & \mI \end{bmatrix}}_{\mZ} = 
\underbrace{\begin{bmatrix} \mM/\mD & \mZero \\ \mZero & \mD \end{bmatrix}}_{\mW}
\end{equation}

Basic matrix algebra allows us to re-arrange the terms {TODO cite stolen from murphy?}, taking the inverse of both sides

\begin{align}
(\mX \mM \mZ)^{-1} &= \mW^{-1} \\
\mZ^{-1} \mM^{-1} \mX^{-1} &= \mW^{-1} \\
\mM^{-1} &= \mZ \mW^{-1} \mX
\end{align}

Which gives us the final form, making use of the fact that to invert a diagonal matrix we just need to invert its diagonal

\begin{equation} \label{eq:block-inverse}
\mM^{-1} = \begin{bmatrix} \mA & \mB \\ \mC & \mD \end{bmatrix}^{-1} =
\begin{bmatrix} \mI & \mZero \\ -\mD^{-1} \mC & \mI \end{bmatrix}
\begin{bmatrix} (\mM/\mD)^{-1} & \mZero \\ \mZero & \mD^{-1} \end{bmatrix}
\begin{bmatrix} \mI & -\mB \mD^{-1} & \\ \mZero & \mI \end{bmatrix}
\end{equation}

\end{proof}



\section{TODO Linear Gaussian transform - change of variables}

\begin{align}
P(\vx \in \mM) = \int_\mM \frac{1}{(2 \pi)^{D/2} |\mSigma|^{1/2}|} exp \left(-\frac{1}{2} (\vx - \vmu)^T \mSigma^{-1} (\vx - \vmu) \right) d \vx \\
P(\vx \in \mA^{-1} \mM) = \int_{\mA^{-1} \mM} \frac{1}{(2 \pi)^{D/2} |\mSigma|^{1/2}} \exp \left(-\frac{1}{2} (\vu - \vmu)^T \mSigma^{-1} (\vu - \vmu) \right) d \vu \\
\vu = \mA \vx
\end{align}